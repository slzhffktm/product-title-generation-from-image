{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/std.py:666: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import ast\n",
    "import heapq\n",
    "from copy import deepcopy\n",
    "from math import log\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "import pkbar\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.autonotebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from skimage import io\n",
    "from sklearn.metrics import hamming_loss, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk import FreqDist\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Using CUDA\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = '<start>'\n",
    "end_token = '<end>'\n",
    "unknown_token = '<unk>'\n",
    "padding_token = '<pad>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/styles_tags_pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>masterCategory</th>\n",
       "      <th>subCategory</th>\n",
       "      <th>articleType</th>\n",
       "      <th>baseColour</th>\n",
       "      <th>title</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>file_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>tags_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1163</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Tshirts</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Nike Sahara Team India Fanwear Round Neck Jersey</td>\n",
       "      <td>['&lt;start&gt;', 'nike', 'sahara', 'team', 'india',...</td>\n",
       "      <td>1163.jpg</td>\n",
       "      <td>['nike', 'team', 'india', 'round', 'neck', 'je...</td>\n",
       "      <td>[2.3143535e-07, 2.3702476e-09, 2.986898e-07, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1164</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Tshirts</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Nike Men Blue T20 Indian Cricket Jersey</td>\n",
       "      <td>['&lt;start&gt;', 'nike', 'men', 'blue', 'indian', '...</td>\n",
       "      <td>1164.jpg</td>\n",
       "      <td>['nike', 'men', 'blue', 'indian', 'cricket', '...</td>\n",
       "      <td>[2.2555818e-07, 1.8278894e-09, 7.16435e-09, 3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1165</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Tshirts</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Nike Mean Team India Cricket Jersey</td>\n",
       "      <td>['&lt;start&gt;', 'nike', 'mean', 'team', 'india', '...</td>\n",
       "      <td>1165.jpg</td>\n",
       "      <td>['nike', 'team', 'india', 'cricket', 'jersey']</td>\n",
       "      <td>[0.00035982736, 2.8710444e-06, 5.1504063e-05, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1525</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Bags</td>\n",
       "      <td>Backpacks</td>\n",
       "      <td>Navy Blue</td>\n",
       "      <td>Puma Deck Navy Blue Backpack</td>\n",
       "      <td>['&lt;start&gt;', 'puma', 'deck', 'navy', 'blue', 'b...</td>\n",
       "      <td>1525.jpg</td>\n",
       "      <td>['puma', 'navy', 'blue', 'backpack']</td>\n",
       "      <td>[1.9060193e-05, 8.293974e-09, 9.6082715e-08, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1526</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Bags</td>\n",
       "      <td>Backpacks</td>\n",
       "      <td>Black</td>\n",
       "      <td>Puma Big Cat Backpack Black</td>\n",
       "      <td>['&lt;start&gt;', 'puma', 'big', 'cat', 'backpack', ...</td>\n",
       "      <td>1526.jpg</td>\n",
       "      <td>['puma', 'big', 'cat', 'backpack', 'black']</td>\n",
       "      <td>[0.0015358106, 1.2226741e-07, 7.6661183e-07, 9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id masterCategory subCategory articleType baseColour  \\\n",
       "0  1163        Apparel     Topwear     Tshirts       Blue   \n",
       "1  1164        Apparel     Topwear     Tshirts       Blue   \n",
       "2  1165        Apparel     Topwear     Tshirts       Blue   \n",
       "3  1525    Accessories        Bags   Backpacks  Navy Blue   \n",
       "4  1526    Accessories        Bags   Backpacks      Black   \n",
       "\n",
       "                                              title  \\\n",
       "0  Nike Sahara Team India Fanwear Round Neck Jersey   \n",
       "1           Nike Men Blue T20 Indian Cricket Jersey   \n",
       "2               Nike Mean Team India Cricket Jersey   \n",
       "3                      Puma Deck Navy Blue Backpack   \n",
       "4                       Puma Big Cat Backpack Black   \n",
       "\n",
       "                                           tokenized file_name  \\\n",
       "0  ['<start>', 'nike', 'sahara', 'team', 'india',...  1163.jpg   \n",
       "1  ['<start>', 'nike', 'men', 'blue', 'indian', '...  1164.jpg   \n",
       "2  ['<start>', 'nike', 'mean', 'team', 'india', '...  1165.jpg   \n",
       "3  ['<start>', 'puma', 'deck', 'navy', 'blue', 'b...  1525.jpg   \n",
       "4  ['<start>', 'puma', 'big', 'cat', 'backpack', ...  1526.jpg   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['nike', 'team', 'india', 'round', 'neck', 'je...   \n",
       "1  ['nike', 'men', 'blue', 'indian', 'cricket', '...   \n",
       "2     ['nike', 'team', 'india', 'cricket', 'jersey']   \n",
       "3               ['puma', 'navy', 'blue', 'backpack']   \n",
       "4        ['puma', 'big', 'cat', 'backpack', 'black']   \n",
       "\n",
       "                                           tags_pred  \n",
       "0  [2.3143535e-07, 2.3702476e-09, 2.986898e-07, 3...  \n",
       "1  [2.2555818e-07, 1.8278894e-09, 7.16435e-09, 3....  \n",
       "2  [0.00035982736, 2.8710444e-06, 5.1504063e-05, ...  \n",
       "3  [1.9060193e-05, 8.293974e-09, 9.6082715e-08, 2...  \n",
       "4  [0.0015358106, 1.2226741e-07, 7.6661183e-07, 9...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subCategory</th>\n",
       "      <th>articleType</th>\n",
       "      <th>baseColour</th>\n",
       "      <th>title</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>file_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>tags_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>masterCategory</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accessories</th>\n",
       "      <td>11286</td>\n",
       "      <td>11286</td>\n",
       "      <td>11286</td>\n",
       "      <td>11286</td>\n",
       "      <td>11286</td>\n",
       "      <td>11286</td>\n",
       "      <td>11286</td>\n",
       "      <td>11286</td>\n",
       "      <td>11286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apparel</th>\n",
       "      <td>21395</td>\n",
       "      <td>21395</td>\n",
       "      <td>21395</td>\n",
       "      <td>21389</td>\n",
       "      <td>21395</td>\n",
       "      <td>21395</td>\n",
       "      <td>21395</td>\n",
       "      <td>21395</td>\n",
       "      <td>21395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Footwear</th>\n",
       "      <td>9220</td>\n",
       "      <td>9220</td>\n",
       "      <td>9220</td>\n",
       "      <td>9220</td>\n",
       "      <td>9220</td>\n",
       "      <td>9220</td>\n",
       "      <td>9220</td>\n",
       "      <td>9220</td>\n",
       "      <td>9220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Free Items</th>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Home</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personal Care</th>\n",
       "      <td>2399</td>\n",
       "      <td>2399</td>\n",
       "      <td>2399</td>\n",
       "      <td>2395</td>\n",
       "      <td>2399</td>\n",
       "      <td>2399</td>\n",
       "      <td>2399</td>\n",
       "      <td>2399</td>\n",
       "      <td>2399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sporting Goods</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  subCategory  articleType  baseColour  title  tokenized  \\\n",
       "masterCategory                                                                  \n",
       "Accessories     11286        11286        11286       11286  11286      11286   \n",
       "Apparel         21395        21395        21395       21389  21395      21395   \n",
       "Footwear         9220         9220         9220        9220   9220       9220   \n",
       "Free Items        105          105          105         105    105        105   \n",
       "Home                1            1            1           1      1          1   \n",
       "Personal Care    2399         2399         2399        2395   2399       2399   \n",
       "Sporting Goods     25           25           25          25     25         25   \n",
       "\n",
       "                file_name   tags  tags_pred  \n",
       "masterCategory                               \n",
       "Accessories         11286  11286      11286  \n",
       "Apparel             21395  21395      21395  \n",
       "Footwear             9220   9220       9220  \n",
       "Free Items            105    105        105  \n",
       "Home                    1      1          1  \n",
       "Personal Care        2399   2399       2399  \n",
       "Sporting Goods         25     25         25  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"masterCategory\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_master_category = [\n",
    "    \"Home\",\n",
    "    \"Sporting Goods\",\n",
    "    \"Free Items\"\n",
    "]\n",
    "\n",
    "df = df[~df.masterCategory.isin(removed_master_category)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert stringified-list-type columns back to list\n",
    "df.tokenized = df.tokenized.apply(lambda tokens: ast.literal_eval(tokens))\n",
    "df.tags_pred = df.tags_pred.apply(lambda tags: ast.literal_eval(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.tokenized\n",
    "semantic_inputs = df.tags_pred\n",
    "file_names = df.file_name\n",
    "categories = df.subCategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens_frequency = FreqDist()\n",
    "# for tokens in labels:\n",
    "#     tokens_frequency += FreqDist(tokens)\n",
    "\n",
    "# word_list = [token for token, freq in tokens_frequency.most_common()]\n",
    "\n",
    "# word_list = word_list[2:]\n",
    "\n",
    "# df_word_list = pd.DataFrame({\"word_list\": sorted(word_list)})\n",
    "\n",
    "# df_word_list.head()\n",
    "\n",
    "# df_word_list.to_csv(\"data/word_list.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_list = pd.read_csv(\"data/word_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a-line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaa-chhe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaliya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aandhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaren</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word_list\n",
       "0    a-line\n",
       "1  aaa-chhe\n",
       "2    aaliya\n",
       "3    aandhi\n",
       "4     aaren"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, labels_train, labels_val = train_test_split(list(zip(file_names, semantic_inputs)), labels, test_size=0.3, random_state=105, stratify=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31010"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names_train = X_train[:, 0]\n",
    "semantic_inputs_train = X_train[:, 1]\n",
    "file_names_val = X_val[:, 0]\n",
    "semantic_inputs_val = X_val[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'file_names': file_names_val}).to_csv('data/other_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = list(labels_train)\n",
    "labels_val = list(labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del file_names\n",
    "del labels\n",
    "del semantic_inputs\n",
    "del categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Simple vocabulary wrapper.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.idx = 0\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if not word in self.word2idx:\n",
    "            self.word2idx[word] = self.idx\n",
    "            self.idx2word[self.idx] = word\n",
    "            self.idx += 1\n",
    "\n",
    "    def get_word(self, idx):\n",
    "        return self.idx2word[idx]\n",
    "\n",
    "    def __call__(self, word):\n",
    "        if not word in self.word2idx:\n",
    "            return self.word2idx['<unk>']\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(word_list):\n",
    "    \n",
    "    vocab = Vocabulary()\n",
    "    \n",
    "    vocab.add_word(start_token)\n",
    "    vocab.add_word(end_token)\n",
    "    vocab.add_word(unknown_token)\n",
    "    vocab.add_word(padding_token)\n",
    "    \n",
    "    for word in word_list:\n",
    "        vocab.add_word(word)\n",
    "        \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab(df_word_list.word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Caption Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tensor1d(tensor, split):\n",
    "    r\"\"\"Split 1D of tensor into N split\n",
    "\n",
    "    Arguments\n",
    "        tensor (Pytorch.Tensor) : tensor to split\n",
    "        split  (int) : number of split\n",
    "    Return\n",
    "        array of splitted tensor with N elements of array\n",
    "    \"\"\"\n",
    "    return [\n",
    "        tensor[:split],\n",
    "        tensor[split: split * 2],\n",
    "        tensor[split * 2: split * 3],\n",
    "        tensor[split * 3:],\n",
    "    ]\n",
    "\n",
    "\n",
    "def split_tensor2d(tensor, split, front=False):\n",
    "    r\"\"\"Split 2D of tensor into N split of 2D tensor\n",
    "\n",
    "    Arguments\n",
    "        tensor (Pytorch.Tensor) : tensor to split\n",
    "        split  (int) : number of split\n",
    "        front  (bool) : split axis 0 if True else axis 1\n",
    "    Return\n",
    "        array of splitted 2D tensor with N elements of array\n",
    "    \"\"\"\n",
    "\n",
    "    if front:\n",
    "        return [\n",
    "            tensor[:split, :],\n",
    "            tensor[split: split * 2, :],\n",
    "            tensor[split * 2: split * 3, :],\n",
    "            tensor[split * 3:, :],\n",
    "        ]\n",
    "\n",
    "    return [\n",
    "        tensor[:, :split],\n",
    "        tensor[:, split: split * 2],\n",
    "        tensor[:, split * 2: split * 3],\n",
    "        tensor[:, split * 3:],\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexto1hot(vocab_len, index):\n",
    "    #print(\"index type: \")\n",
    "    if isinstance(index, int) == False:\n",
    "        n = len(index)\n",
    "        #print(\"making a 1hot encoding of shape: \" + str(n) + \",\" + str(vocab_len) )\n",
    "        one_hot = np.zeros([n,vocab_len])\n",
    "        #can this be optimized?\n",
    "        for i in range(n):\n",
    "            one_hot[i,index[i]]=1\n",
    "        \n",
    "        return one_hot\n",
    "    else:\n",
    "        one_hot = np.zeros([vocab_len])\n",
    "        one_hot[index] = 1\n",
    "        \n",
    "        return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLSTM(nn.Module):\n",
    "    def __init__(self, dim_word_emb, dim_lang_lstm, dim_image_feats, nb_hidden):\n",
    "        super(AttentionLSTM, self).__init__()\n",
    "        \n",
    "        self.lstm_cell = nn.LSTMCell(dim_lang_lstm+dim_image_feats+dim_word_emb,\n",
    "                                     nb_hidden,\n",
    "                                     bias=True)\n",
    "        \n",
    "    def forward(self, h1, c1, h2, v_mean, word_emb):\n",
    "        #print(h2.shape)\n",
    "        #print(v_mean.shape)\n",
    "        #print(word_emb.shape)\n",
    "        input_feats = torch.cat((h2, v_mean, word_emb),dim=1)\n",
    "        h_out, c_out = self.lstm_cell(input_feats, (h1, c1))\n",
    "        \n",
    "        return h_out, c_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attend(nn.Module):\n",
    "    def __init__(self, dim_image_feats, dim_att_lstm, nb_hidden):\n",
    "        super(Attend, self).__init__()\n",
    "    \n",
    "        self.fc_image_feats = nn.Linear(dim_image_feats, nb_hidden, bias=False)\n",
    "        self.fc_att_lstm = nn.Linear(dim_att_lstm, nb_hidden, bias=False)\n",
    "        self.act_tan = nn.Tanh()\n",
    "        self.fc_att = nn.Linear(nb_hidden, 1)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, image_feats, h1):\n",
    "        nb_batch, nb_feats, feat_dim = image_feats.size()\n",
    "        att_lstm_emb = self.fc_att_lstm(h1).unsqueeze(1)\n",
    "        image_feats_emb = self.fc_image_feats(image_feats)\n",
    "        all_feats_emb = image_feats_emb + att_lstm_emb.repeat(1,nb_feats,1)\n",
    "\n",
    "        activate_feats = self.act_tan(all_feats_emb)\n",
    "        unnorm_attention = self.fc_att(activate_feats)\n",
    "        normed_attention = self.softmax(unnorm_attention)\n",
    "\n",
    "        #print(normed_attention.shape)\n",
    "        #print(nb_feats)\n",
    "        #print(image_feats.shape)\n",
    "        #weighted_feats = normed_attention.repeat(1,1,nb_feats) * image_feats\n",
    "        weighted_feats = normed_attention * image_feats\n",
    "        #print(weighted_feats.shape)\n",
    "        attended_image_feats = weighted_feats.sum(dim=1)\n",
    "        #print(attended_image_feats.shape)\n",
    "    \n",
    "        return attended_image_feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCNCell(nn.Module):\n",
    "    r\"\"\"Custom Cell for Implementing Semantic Compositional Networks\n",
    "\n",
    "    Arguments\n",
    "        input_size (int): size of input\n",
    "        hidden_size (int): size of embedding\n",
    "        semantic_size (int): size of semantic\n",
    "        factor_size (int): size of factor\n",
    "        bias (boolean, optional): use bias?\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, semantic_size, factor_size, bias=True):\n",
    "        super(SCNCell, self).__init__()\n",
    "\n",
    "        self.factor_size = factor_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.semantic_size = semantic_size\n",
    "\n",
    "        self.weight_ia = nn.Parameter(\n",
    "            torch.Tensor(input_size, 4 * factor_size))\n",
    "        self.weight_ib = nn.Parameter(\n",
    "            torch.Tensor(semantic_size, 4 * factor_size))\n",
    "        self.weight_ic = nn.Parameter(\n",
    "            torch.Tensor(hidden_size, 4 * factor_size))\n",
    "\n",
    "        self.weight_ha = nn.Parameter(\n",
    "            torch.Tensor(hidden_size, 4 * factor_size))\n",
    "        self.weight_hb = nn.Parameter(\n",
    "            torch.Tensor(semantic_size, 4 * factor_size))\n",
    "        self.weight_hc = nn.Parameter(\n",
    "            torch.Tensor(hidden_size, 4 * factor_size))\n",
    "\n",
    "        if bias:\n",
    "            self.bias_ih = nn.Parameter(torch.Tensor(4 * hidden_size))\n",
    "            self.bias_hh = nn.Parameter(torch.Tensor(4 * hidden_size))\n",
    "        else:\n",
    "            self.register_parameter('bias_ih', None)\n",
    "            self.register_parameter('bias_hh', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def forward(self, h1, v_hat, semantic_input, hx=None):\n",
    "        r\"\"\"Forward propagation.\n",
    "\n",
    "        Arguments\n",
    "            wemb_input (torch.Tensor): word embedding input, a tensor of dimension (batch_size, input_size)\n",
    "            semantic_input (torch.Tensor): semantic concepts input, a tensor of dimension (batch_size, semantic_dim)\n",
    "        Returns\n",
    "            torch.Tensor: next hidden state, next cell state\n",
    "        \"\"\"\n",
    "\n",
    "        input_feats = torch.cat((h1, v_hat), dim=1)\n",
    "        \n",
    "        self.check_forward_input(input_feats)\n",
    "\n",
    "        [ia_i, ia_f, ia_o, ia_c] = split_tensor2d(\n",
    "            self.weight_ia, self.factor_size)\n",
    "        [ib_i, ib_f, ib_o, ib_c] = split_tensor2d(\n",
    "            self.weight_ib, self.factor_size)\n",
    "        [ic_i, ic_f, ic_o, ic_c] = split_tensor2d(\n",
    "            self.weight_ic, self.factor_size)\n",
    "        [b_ii, b_if, b_io, b_ic] = split_tensor1d(\n",
    "            self.bias_ih, self.hidden_size)\n",
    "\n",
    "        tmp1_i = (input_feats @ ia_i)\n",
    "        tmp1_f = (input_feats @ ia_f)\n",
    "        tmp1_o = (input_feats @ ia_o)\n",
    "        tmp1_c = (input_feats @ ia_c)\n",
    "\n",
    "        tmp2_i = (semantic_input @ ib_i).unsqueeze(0)\n",
    "        tmp2_f = (semantic_input @ ib_f).unsqueeze(0)\n",
    "        tmp2_o = (semantic_input @ ib_o).unsqueeze(0)\n",
    "        tmp2_c = (semantic_input @ ib_c).unsqueeze(0)\n",
    "\n",
    "        state_below_i = ((tmp1_i * tmp2_i) @ ic_i.t()) + b_ii\n",
    "        state_below_f = ((tmp1_f * tmp2_f) @ ic_f.t()) + b_if\n",
    "        state_below_o = ((tmp1_o * tmp2_o) @ ic_o.t()) + b_io\n",
    "        state_below_c = ((tmp1_c * tmp2_c) @ ic_c.t()) + b_ic\n",
    "\n",
    "        x_i = state_below_i.squeeze(0)\n",
    "        x_f = state_below_f.squeeze(0)\n",
    "        x_o = state_below_o.squeeze(0)\n",
    "        x_c = state_below_c.squeeze(0)\n",
    "\n",
    "        if hx is None:\n",
    "            hx = input_feats.new_zeros(input_feats.size(\n",
    "                0), self.hidden_size, requires_grad=False)\n",
    "            hx = (hx, hx)\n",
    "\n",
    "        self.check_forward_hidden(x_i, hx[0], '[0]')\n",
    "        self.check_forward_hidden(x_i, hx[1], '[1]')\n",
    "\n",
    "        self.check_forward_hidden(x_f, hx[0], '[0]')\n",
    "        self.check_forward_hidden(x_f, hx[1], '[1]')\n",
    "\n",
    "        self.check_forward_hidden(x_o, hx[0], '[0]')\n",
    "        self.check_forward_hidden(x_o, hx[1], '[1]')\n",
    "\n",
    "        self.check_forward_hidden(x_c, hx[0], '[0]')\n",
    "        self.check_forward_hidden(x_c, hx[1], '[1]')\n",
    "\n",
    "        return self.recurrent_step(x_i, x_f, x_o, x_c, semantic_input, hx)\n",
    "\n",
    "    def recurrent_step(self, x_i, x_f, x_o, x_c, semantic_input, hx):\n",
    "        r\"\"\"Recurrent step helper for forward propagation.\n",
    "\n",
    "        Arguments\n",
    "            x_i, x_f, x_o, x_c (torch.Tensor): factorized input, containing information from word embedding and semantic concepts, tensors of dimension (batch_size, input_size)\n",
    "            semantic_input (torch.Tensor): semantic concepts input, a tensor of dimension (batch_size, semantic_dim)\n",
    "            h_x (torch.Tensor): initial value of hidden and cell state\n",
    "        Returns\n",
    "            torch.Tensor: next hidden state, next cell state\n",
    "        \"\"\"\n",
    "\n",
    "        h_, c_ = hx\n",
    "\n",
    "        [ha_i, ha_f, ha_o, ha_c] = split_tensor2d(\n",
    "            self.weight_ha, self.factor_size)\n",
    "        [hb_i, hb_f, hb_o, hb_c] = split_tensor2d(\n",
    "            self.weight_hb, self.factor_size)\n",
    "        [hc_i, hc_f, hc_o, hc_c] = split_tensor2d(\n",
    "            self.weight_hc, self.factor_size)\n",
    "        [b_hi, b_hf, b_ho, b_hc] = split_tensor1d(\n",
    "            self.bias_hh, self.hidden_size)\n",
    "\n",
    "        preact_i = (h_ @ ha_i) * (semantic_input @ hb_i)\n",
    "        preact_i = (preact_i @ hc_i.t()) + x_i + b_hi\n",
    "\n",
    "        preact_f = (h_ @ ha_f) * (semantic_input @ hb_f)\n",
    "        preact_f = (preact_f @ hc_f.t()) + x_f + b_hf\n",
    "\n",
    "        preact_o = (h_ @ ha_o) * (semantic_input @ hb_o)\n",
    "        preact_o = (preact_o @ hc_o.t()) + x_o + b_ho\n",
    "\n",
    "        preact_c = (h_ @ ha_c) * (semantic_input @ hb_c)\n",
    "        preact_c = (preact_c @ hc_c.t()) + x_c + b_hc\n",
    "\n",
    "        i = torch.sigmoid(preact_i)\n",
    "        f = torch.sigmoid(preact_f)\n",
    "        o = torch.sigmoid(preact_o)\n",
    "        c = torch.tanh(preact_c)\n",
    "\n",
    "        c = f * c_ + i * c\n",
    "        h = o * torch.tanh(c)\n",
    "\n",
    "        return h, c\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            torch.nn.init.uniform_(weight, -stdv, stdv)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        s = '{input_size}, {hidden_size}'\n",
    "        if 'bias' in self.__dict__ and self.bias is not True:\n",
    "            s += ', bias={bias}'\n",
    "        if 'nonlinearity' in self.__dict__ and self.nonlinearity != \"tanh\":\n",
    "            s += ', nonlinearity={nonlinearity}'\n",
    "        return s.format(**self.__dict__)\n",
    "\n",
    "    def check_forward_input(self, input):\n",
    "        if input.size(1) != self.input_size:\n",
    "            raise RuntimeError(\n",
    "                \"input has inconsistent input_size: got {}, expected {}\".format(\n",
    "                    input.size(1), self.input_size))\n",
    "\n",
    "    def check_forward_hidden(self, input, hx, hidden_label=''):\n",
    "        if input.size(0) != hx.size(0):\n",
    "            raise RuntimeError(\n",
    "                \"Input batch size {} doesn't match hidden{} batch size {}\".format(\n",
    "                    input.size(0), hidden_label, hx.size(0)))\n",
    "\n",
    "        if hx.size(1) != self.hidden_size:\n",
    "            raise RuntimeError(\n",
    "                \"hidden{} has inconsistent hidden_size: got {}, expected {}\".format(\n",
    "                    hidden_label, hx.size(1), self.hidden_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence is class for beam search\n",
    "class Sentence(object):\n",
    "    def __init__(self, max_nb_words, beam_width, end_word, vocab):\n",
    "        self.max_nb_words = max_nb_words\n",
    "        self.beam_width = beam_width\n",
    "        self.end_word = end_word\n",
    "        self.vocab = vocab\n",
    "\n",
    "        self.words = []\n",
    "        self.probability = 0\n",
    "        self.ended = False\n",
    "\n",
    "        self.act = nn.Softmax(dim=1)\n",
    "\n",
    "    def update_words(self, s, state, y):\n",
    "        y = self.act(y)\n",
    "        new_s = []\n",
    "        for i in range(self.beam_width):\n",
    "            val, idx = y.max(dim=1)\n",
    "            y[0, idx] -= val\n",
    "            current_word = y.clone()\n",
    "            current_word[0,:] = 0\n",
    "            current_word[0,idx] = 1\n",
    "            s2 = s.copy()\n",
    "            s2.update_state(val, state, current_word)\n",
    "            new_s.append(s2)\n",
    "            if s2.ended:\n",
    "                break\n",
    "        return new_s\n",
    "\n",
    "    def update_state(self, p, state, current_word):\n",
    "        self.state = [s.clone() for s in state]\n",
    "        self.words.append(current_word)\n",
    "        self._update_probability(p)\n",
    "        self._update_finished()\n",
    "\n",
    "    def get_states(self):\n",
    "        return self.state, self.words[-1]\n",
    "\n",
    "    def extract_sentence(self):\n",
    "        sentence = []\n",
    "        for w in self.words:\n",
    "            idx = w.max(1)[1].item()\n",
    "            sentence.append(self.vocab.get_word(idx))\n",
    "        return [self.probability, sentence]\n",
    "\n",
    "    def _update_probability(self, p):\n",
    "        self.probability += log(p, 2)\n",
    "\n",
    "    def _update_finished(self):\n",
    "        n = len(self.words)\n",
    "        f = self.words[-1]\n",
    "        if (n > self.max_nb_words) or (f == self.end_word).all():\n",
    "            self.ended = True\n",
    "\n",
    "    def copy(self):\n",
    "        new = Sentence(self.max_nb_words,\n",
    "                       self.beam_width,\n",
    "                       self.end_word,\n",
    "                       self.vocab)\n",
    "        new.words = [w.clone() for w in self.words]\n",
    "        new.probability = self.probability\n",
    "        return new\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.probability < other.probability\n",
    "\n",
    "    def __repr__(self):\n",
    "        s = ''\n",
    "        for w in self.words:\n",
    "            idx = w.max(1)[1].item()\n",
    "            s += \"{}, \".format(self.vocab.get_word(idx))\n",
    "        return s\n",
    "\n",
    "\n",
    "class Beam(object):\n",
    "    def __init__(self, beam_width):\n",
    "        self.beam_width = beam_width\n",
    "        self.heap = []\n",
    "\n",
    "    def push(self, s):\n",
    "        s.probability *= -1\n",
    "        heapq.heappush(self.heap, s)\n",
    "\n",
    "    def pop(self):\n",
    "        s = heapq.heappop(self.heap)\n",
    "        s.probability *= -1\n",
    "        return s\n",
    "\n",
    "    def trim(self):\n",
    "        h2 = []\n",
    "        for i in range(self.beam_width):\n",
    "            if len(self.heap) == 0:\n",
    "                break\n",
    "            heapq.heappush(h2, heapq.heappop(self.heap))\n",
    "        self.heap=h2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.heap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictWord(nn.Module):\n",
    "    def __init__(self, dim_language_lstm, dict_size):\n",
    "        super(PredictWord, self).__init__()\n",
    "        self.fc = nn.Linear(dim_language_lstm, dict_size)\n",
    "        \n",
    "    def forward(self, h2):\n",
    "        y = self.fc(h2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_zeros(shape, cuda=False):\n",
    "    zeros = torch.zeros(shape)\n",
    "    if cuda:\n",
    "        zeros = zeros.cuda()\n",
    "    return zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullProductDataset(Dataset):\n",
    "    \"\"\"Dataset for product with it's image, title token, and semantic input.\"\"\"\n",
    "\n",
    "    def __init__(self, file_names, semantic_inputs, titles, image_dir, vocab, transformer=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            image_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied on an image.\n",
    "        \"\"\"\n",
    "        self.file_names = file_names\n",
    "        self.semantic_inputs = semantic_inputs\n",
    "        self.titles = titles\n",
    "        self.image_dir = image_dir\n",
    "        self.transformer = transformer\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.image_dir, self.file_names[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        if self.transformer:\n",
    "            image = self.transformer(image)\n",
    "        \n",
    "        semantic_input = self.semantic_inputs[idx]\n",
    "        semantic_input = torch.tensor(semantic_input, dtype=torch.float)\n",
    "        \n",
    "        title = [vocab(token) for token in self.titles[idx]]\n",
    "        title = torch.tensor(title)\n",
    "     \n",
    "        return image, semantic_input, title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(sample):\n",
    "    \"\"\"Creates mini-batch tensors from the list of tuples (image, caption).\n",
    "    \n",
    "    We should build custom collate_fn rather than using default collate_fn, \n",
    "    because merging caption (including padding) is not supported in default.\n",
    "    Args:\n",
    "        data: list of tuple (image, caption). \n",
    "            - feature: torch tensor of shape (36,2048).\n",
    "            - caption: torch tensor of shape (?); variable length.\n",
    "    Returns:\n",
    "        features: torch tensor of shape (batch_size, 36, 2048).\n",
    "        targets: torch tensor of shape (batch_size, padded_length).\n",
    "        lengths: list; valid length for each padded caption.\n",
    "    \"\"\"\n",
    "    # Sort data list by caption length (descending order).\n",
    "    sample.sort(key=lambda x: len(x[2]), reverse=True)\n",
    "    images, semantic_inputs, titles = zip(*sample)\n",
    "    \n",
    "    # Merge captions (from tuple of 1D tensor to 2D tensor).\n",
    "    lengths = [len(title) for title in titles]\n",
    "\n",
    "    targets = torch.zeros(len(titles), max(lengths)).long()\n",
    "    for i, title in enumerate(titles):\n",
    "        end = lengths[i]\n",
    "        targets[i, :end] = title[:end]\n",
    "\n",
    "    return torch.stack(images), torch.stack(semantic_inputs), targets, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (60, 80) torch.Size([1000]) torch.Size([7])\n",
      "1 (60, 80) torch.Size([1000]) torch.Size([7])\n",
      "2 (60, 80) torch.Size([1000]) torch.Size([9])\n",
      "3 (60, 80) torch.Size([1000]) torch.Size([7])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test dataset\n",
    "dataset = FullProductDataset(file_names_train, semantic_inputs_train, labels_train, \"data/images\", vocab)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    image, semantic_input, title = dataset[i]\n",
    "\n",
    "    print(i, image.size, semantic_input.shape, title.shape)\n",
    "\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Sample #{}'.format(i))\n",
    "    ax.axis('off')\n",
    "    plt.imshow(image)\n",
    "    \n",
    "    if i == 3:\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transformer = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomResizedCrop(224, scale=(1.0, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Encoder Model from Image Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTagger(nn.Module):\n",
    "    r\"\"\"Tagger Encoder extends ResNet152 Model.\n",
    "\n",
    "    Arguments:\n",
    "        semantic_size (int, optional): size of semantic size\n",
    "        dropout (float, optional): dropout rate\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, semantic_size=1000, dropout=0.15):\n",
    "        super(ImageTagger, self).__init__()\n",
    "        self.semantic_size = semantic_size\n",
    "\n",
    "        # Using pre-trained ImageNet\n",
    "        resnet = torchvision.models.resnet152(pretrained=True)\n",
    "\n",
    "        # Remove linear layers (since we're not doing classification)\n",
    "        modules = list(resnet.children())[:-1]\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.linear = nn.Linear(2048, semantic_size)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.fine_tune()\n",
    "\n",
    "    def forward(self, images):\n",
    "        r\"\"\"Forward propagation.\n",
    "\n",
    "        Arguments\n",
    "            images (torch.Tensor): images, a tensor of dimensions (batch_size, 3, image_size, image_size)\n",
    "        Returns \n",
    "            torch.Tensor: probabilites of tags (batch_size, 1000)\n",
    "        \"\"\"\n",
    "        out = self.resnet(images)\n",
    "        out = out.view(out.size(0), -1)   # (batch_size, 2048)\n",
    "        out = self.dropout(out)           # (batch_size, 2048)\n",
    "        out = self.linear(out)            # (batch_size, 1000)\n",
    "        out = self.sigmoid(out)           # (batch_size, 1000)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def fine_tune(self, fine_tune=True):\n",
    "        r\"\"\"Allow or prevent the computation of gradients for convolutional blocks 2 through 4 of the encoder.\n",
    "\n",
    "        Arguments\n",
    "            fine_tune (boolean): Allow fine tuning?\n",
    "        \"\"\"\n",
    "        for p in self.resnet.parameters():\n",
    "            p.requires_grad = False\n",
    "        # If fine-tuning, only fine-tune convolutional blocks 2 through 4\n",
    "        for c in list(self.resnet.children())[5:]:\n",
    "            for p in c.parameters():\n",
    "                p.requires_grad = fine_tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tagger = ImageTagger()\n",
    "image_tagger = image_tagger.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tagger.load_state_dict(torch.load(\"models/image_tagger.best_1\")['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = image_tagger.resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptionModel(nn.Module):\n",
    "\n",
    "    def __init__(self, dict_size, image_feature_dim, vocab, tf_ratio):\n",
    "        super(CaptionModel, self).__init__()\n",
    "        self.dict_size = dict_size\n",
    "        self.image_feature_dim = image_feature_dim\n",
    "        self.vocab = vocab\n",
    "        self.tf_ratio = tf_ratio\n",
    "\n",
    "        self.embed_word = nn.Linear(dict_size, WORD_EMB_DIM, bias=False)\n",
    "\n",
    "        self.lstm2 = SCNCell(WORD_EMB_DIM+image_feature_dim,\n",
    "                             NB_HIDDEN_LSTM2,\n",
    "                             SEMANTIC_DIM,\n",
    "                             FACTORED_DIM,\n",
    "                             bias=True)\n",
    "\n",
    "        self.predict_word = PredictWord(NB_HIDDEN_LSTM2, dict_size)\n",
    "\n",
    "        self.h2 = torch.nn.Parameter(torch.zeros(1, NB_HIDDEN_LSTM2))\n",
    "        self.c2 = torch.nn.Parameter(torch.zeros(1, NB_HIDDEN_LSTM2))\n",
    "    \n",
    "    def forward(self, image_feats, nb_timesteps, semantic_input, true_words, beam=None):\n",
    "        if beam is not None:\n",
    "            return self.beam_search(image_feats, nb_timesteps, beam, semantic_input)\n",
    "\n",
    "        nb_batch, nb_image_feats, _ = image_feats.size()\n",
    "        use_cuda = image_feats.is_cuda\n",
    "\n",
    "        v_mean = image_feats.mean(dim=1)\n",
    "\n",
    "        state, current_word = self.init_inference(nb_batch, use_cuda)\n",
    "        y_out = make_zeros((nb_batch, nb_timesteps-1, self.dict_size), cuda = use_cuda)\n",
    "\n",
    "        for t in range(nb_timesteps-1):\n",
    "            y, state = self.forward_one_step(state,\n",
    "                                             current_word,\n",
    "                                             v_mean,\n",
    "                                             image_feats,\n",
    "                                             semantic_input)\n",
    "            y_out[:,t,:] = y\n",
    "\n",
    "            current_word = self.update_current_word(y, true_words, t, use_cuda)\n",
    "\n",
    "        return y_out\n",
    "\n",
    "    def forward_one_step(self, state, current_word, v_mean, image_feats, semantic_input):\n",
    "        h2, c2 = state\n",
    "        word_emb = self.embed_word(current_word)\n",
    "        h2, c2 = self.lstm2(word_emb, v_mean, semantic_input)\n",
    "        y = self.predict_word(h2)\n",
    "        state = [h2, c2]\n",
    "        \n",
    "        return y, state\n",
    "\n",
    "    def update_current_word(self, y, true_words, t, cuda):\n",
    "        use_tf = True if random.random() < self.tf_ratio else False\n",
    "        if use_tf:\n",
    "            next_word = true_words[:,t+1]\n",
    "        else:\n",
    "            next_word = torch.argmax(y, dim=1)\n",
    "\n",
    "        current_word = indexto1hot(len(self.vocab), next_word)\n",
    "        current_word = torch.from_numpy(current_word).float()\n",
    "        \n",
    "        if cuda:\n",
    "            current_word = current_word.cuda()\n",
    "    \n",
    "        return current_word\n",
    "\n",
    "    def init_inference(self, nb_batch, cuda):\n",
    "        start_word = indexto1hot(len(self.vocab), self.vocab('<start>'))\n",
    "        start_word = torch.from_numpy(start_word).float().unsqueeze(0)\n",
    "        start_word = start_word.repeat(nb_batch, 1)\n",
    "\n",
    "        if cuda:\n",
    "            start_word = start_word.cuda()\n",
    "\n",
    "        h2 = self.h2.repeat(nb_batch, 1)\n",
    "        c2 = self.c2.repeat(nb_batch, 1)\n",
    "        state = [h2, c2]\n",
    "\n",
    "        return state, start_word\n",
    "\n",
    "    #########################################\n",
    "    #               BEAM SEARCH             #\n",
    "    #########################################\n",
    "    def beam_search(self, image_features, max_nb_words, beam_width, semantic_input):\n",
    "        # Initialize model\n",
    "        use_cuda = image_features.is_cuda\n",
    "        nb_batch, nb_image_feats, _ = image_features.size()\n",
    "\n",
    "        v_mean = image_features.mean(dim=1)\n",
    "        state, current_word = self.init_inference(nb_batch, use_cuda)\n",
    "\n",
    "        # Initialize beam search\n",
    "        end_word = indexto1hot(len(self.vocab), self.vocab('<end>'))\n",
    "        end_word = torch.from_numpy(end_word).float().unsqueeze(0)\n",
    "        end_word = end_word.cuda() if image_features.is_cuda else end_word\n",
    "        beam = Beam(beam_width)\n",
    "        s = Sentence(max_nb_words, beam_width, end_word, self.vocab)\n",
    "        s.update_state(1.0, state, current_word)\n",
    "        beam.push(s)\n",
    "\n",
    "        # Perform beam search\n",
    "        final_beam = Beam(beam_width)\n",
    "        while len(beam) > 0:\n",
    "            s = beam.pop()\n",
    "            new_sentences = self.update_states(s, image_features, v_mean, semantic_input)\n",
    "            for s in new_sentences:\n",
    "                if s.ended:\n",
    "                    final_beam.push(s)\n",
    "                else:\n",
    "                    beam.push(s)\n",
    "            # Get rid of low scoring sentences\n",
    "            beam.trim() \n",
    "            final_beam.trim()\n",
    "\n",
    "        # Extract final sentence\n",
    "        s = final_beam.pop() # Best sentence on top of heap\n",
    "        sentence = s.extract_sentence()\n",
    "        \n",
    "        return sentence\n",
    "\n",
    "    def update_states(self, s, image_feats, v_mean, semantic_input):\n",
    "        state, current_word = s.get_states()\n",
    "        y, state = self.forward_one_step(state, current_word, v_mean, image_feats, semantic_input)\n",
    "        y = self.remove_consecutive_words(y, current_word)\n",
    "        new_sentences = s.update_words(s, state, y)\n",
    "        return new_sentences\n",
    "\n",
    "    def remove_consecutive_words(self, y, prev_word):\n",
    "        # give previous word low score so as not to repeat words\n",
    "        y = y - 10**10 * prev_word\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_EMB_DIM = 1000\n",
    "NB_HIDDEN_LSTM2 = 1000\n",
    "\n",
    "IMAGE_FEATURE_DIM = 2048\n",
    "FACTORED_DIM = 512\n",
    "SEMANTIC_DIM = 1000\n",
    "\n",
    "TF_RATIO = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_model = CaptionModel(len(vocab), IMAGE_FEATURE_DIM, vocab, TF_RATIO)\n",
    "caption_model = caption_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FullProductDataset(file_names_train, semantic_inputs_train, labels_train, \"data/images\", vocab, image_transformer)\n",
    "val_dataset = FullProductDataset(file_names_val, semantic_inputs_val, labels_val, \"data/images\", vocab, image_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_score(reference, hypothesis, ngram):\n",
    "    weights = [0, 0, 0, 0]\n",
    "    weights[0:ngram] = [1/ngram for i in range(ngram)]\n",
    "    \n",
    "    return sentence_bleu([reference], hypothesis, weights=tuple(weights), auto_reweigh=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, encoder, train_loader, optimizer, kbar):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    nb_batch = len(train_loader)\n",
    "\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, (images, semantic_inputs, captions, lengths) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        semantic_inputs = semantic_inputs.to(device)\n",
    "        captions = captions.to(device)\n",
    "\n",
    "        # forward\n",
    "        image_feats = encoder(images)\n",
    "        image_feats = image_feats.unsqueeze(1).squeeze(3).squeeze(3)\n",
    "        outputs = model(image_feats, len(captions[0]), semantic_inputs, captions)\n",
    "\n",
    "        captions = captions[:, 1:]\n",
    "\n",
    "        decode_lengths = [x-1 for x in lengths]\n",
    "        captions, _, _, _ = pack_padded_sequence(captions, decode_lengths, batch_first=True)\n",
    "        outputs, _, _, _ = pack_padded_sequence(outputs, decode_lengths, batch_first = True)\n",
    "\n",
    "        batch_loss = loss(outputs, captions)\n",
    "        epoch_loss += batch_loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        kbar.update(i, values=[(\"loss\", batch_loss)])\n",
    "        \n",
    "    epoch_loss = epoch_loss / nb_batch \n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_one_epoch(model, val_loader, vocab, beam=None):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    nb_batch = len(train_loader)\n",
    "\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    bleu3_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, semantic_inputs, captions, lengths) in enumerate(val_loader):\n",
    "            images = images.to(device)\n",
    "            semantic_inputs = semantic_inputs.to(device)\n",
    "            captions = captions.to(device)\n",
    "            \n",
    "            image_feats = encoder(images)\n",
    "            image_feats = image_feats.unsqueeze(1).squeeze(3).squeeze(3)\n",
    "            \n",
    "            if beam is not None and (i % 200) == 0:\n",
    "                sentences = model(image_feats, 20, semantic_inputs, beam)\n",
    "                print(sentences)\n",
    "\n",
    "            outputs = model(image_feats, len(captions[0]), semantic_inputs, captions)\n",
    "\n",
    "            for j, (output, caption) in enumerate(zip(outputs, captions)):\n",
    "                caption_list = [vocab.get_word(wid.item()) for wid in caption if wid != 0]                \n",
    "                caption_list = caption_list[:-1]\n",
    "\n",
    "                padded_result = [vocab.get_word(torch.argmax(one_hot_en).item()) for one_hot_en in output]\n",
    "                result_list = []\n",
    "                for word in padded_result:\n",
    "                    if word == '<end>':\n",
    "                        break\n",
    "                    result_list.append(word)\n",
    "                    \n",
    "                bleu3_scores.append(bleu_score(caption_list, result_list, 3))\n",
    "            \n",
    "            decode_lengths = [x-1 for x in lengths]\n",
    "            captions, _, _, _ = pack_padded_sequence(captions, decode_lengths, batch_first=True)\n",
    "            outputs, _, _, _ = pack_padded_sequence(outputs, decode_lengths, batch_first = True)\n",
    "\n",
    "            batch_loss = loss(outputs, captions)\n",
    "            epoch_loss += batch_loss.item()\n",
    "            \n",
    "    bleu3_score_avg = sum(bleu3_scores)/len(bleu3_scores)\n",
    "    epoch_loss = epoch_loss / nb_batch \n",
    "\n",
    "    return bleu3_score_avg, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, vocab, optimizer, scheduler, max_epochs, current_epoch=0):\n",
    "    \n",
    "    since = time.time()\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    train_loss_array = []\n",
    "    val_loss_array = []\n",
    "    val_bleu3_array = []\n",
    "\n",
    "    # some big number\n",
    "    min_val_loss = 10**5\n",
    "    max_bleu3_score = 0\n",
    "    train_epoch_array = []\n",
    "    val_epoch_array = []\n",
    "    \n",
    "#     if current_epoch == 0:\n",
    "#         bleu3_score, val_loss = val_one_epoch(model, val_loader, vocab, beam=None)\n",
    "#         print(\"Validation loss with random initialization. Loss: \" + str(val_loss) + \", BLEU3 score: \" + str(bleu3_score))\n",
    "    \n",
    "    while current_epoch < max_epochs:\n",
    "        current_epoch += 1\n",
    "        \n",
    "        print('Epoch {}/{}'.format(current_epoch, max_epochs))\n",
    "        kbar = pkbar.Kbar(target=len(train_loader), width=32)\n",
    "        \n",
    "        train_loss = train_one_epoch(model, encoder, train_loader, optimizer, kbar)\n",
    "        bleu3_score, val_loss = val_one_epoch(model, val_loader, vocab, beam=None)\n",
    "        \n",
    "        scheduler.step(bleu3_score)\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': current_epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict()\n",
    "        }, \"models/pure_scn.epoch_\" + str(current_epoch))\n",
    "\n",
    "        kbar.add(1, values=[(\"loss\", train_loss), (\"val_loss\", val_loss), (\"BLEU3_score\", bleu3_score)])\n",
    "        \n",
    "        train_loss_array.append(train_loss)\n",
    "        val_loss_array.append(val_loss)\n",
    "        val_bleu3_array.append(bleu3_score)\n",
    "        train_epoch_array.append(current_epoch)\n",
    "        val_epoch_array.append(current_epoch)\n",
    "        \n",
    "        # keep track of the best model and save it\n",
    "        if bleu3_score > max_bleu3_score:\n",
    "            max_bleu3_score = bleu3_score\n",
    "            torch.save({\n",
    "                'epoch': current_epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict()\n",
    "            }, \"models/pure_scn.best_bleu3\")\n",
    "            \n",
    "        if val_loss < min_val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            \n",
    "            \n",
    "    time_elapsed = time.time() - since\n",
    "    print('\\n')\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(min_val_loss))\n",
    "    print('Best val BLEU3 score: {:4f}'.format(max_bleu3_score))\n",
    "    \n",
    "    return model, train_loss_array, val_loss_array, val_bleu3_array, train_epoch_array, val_epoch_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "lr = 3e-4\n",
    "optimizer = optim.Adam(caption_model.parameters(), lr=lr)\n",
    "epochs = 10\n",
    "# optimizer = optim.SGD(model.parameters(),\n",
    "#                       lr=args.lr,\n",
    "#                       momentum = 0.899999976158,\n",
    "#                       weight_decay=0.000500000023749)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'max')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "checkpoint = torch.load(\"models/pure_scn.best\")\n",
    "caption_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "current_epoch = checkpoint['epoch']\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# scheduler.load_state_dict(checkpoint['scheduler_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "969/970 [==============================>.] - ETA: 0s - loss: 2.9386"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "970/970 [================================] - 977s 1s/step - loss: 2.9386 - val_loss: 3.4873 - BLEU3_score: 0.2852\n",
      "Epoch 2/10\n",
      "970/970 [================================] - 973s 1s/step - loss: 1.4738 - val_loss: 3.9545 - BLEU3_score: 0.4206\n",
      "Epoch 3/10\n",
      "970/970 [================================] - 971s 1s/step - loss: 1.1310 - val_loss: 4.1991 - BLEU3_score: 0.4597\n",
      "Epoch 4/10\n",
      "970/970 [================================] - 970s 1s/step - loss: 0.9367 - val_loss: 4.3922 - BLEU3_score: 0.4722\n",
      "Epoch 5/10\n",
      "970/970 [================================] - 970s 1000ms/step - loss: 0.8008 - val_loss: 4.5270 - BLEU3_score: 0.4843\n",
      "Epoch 6/10\n",
      "970/970 [================================] - 970s 1000ms/step - loss: 0.6955 - val_loss: 4.6267 - BLEU3_score: 0.4952\n",
      "Epoch 7/10\n",
      "970/970 [================================] - 970s 1s/step - loss: 0.6146 - val_loss: 4.7404 - BLEU3_score: 0.4980\n",
      "Epoch 8/10\n",
      "970/970 [================================] - 1191s 1s/step - loss: 0.5483 - val_loss: 4.9452 - BLEU3_score: 0.5015\n",
      "Epoch 9/10\n",
      "970/970 [================================] - 973s 1s/step - loss: 0.4909 - val_loss: 5.0586 - BLEU3_score: 0.5032\n",
      "Epoch 10/10\n",
      "970/970 [================================] - 971s 1s/step - loss: 0.4448 - val_loss: 5.1494 - BLEU3_score: 0.5044\n",
      "\n",
      "\n",
      "Training complete in 165m 51s\n",
      "Best val loss: 3.487312\n",
      "Best val BLEU3 score: 0.504404\n"
     ]
    }
   ],
   "source": [
    "caption_model, train_loss_array, val_loss_array, val_bleu3_array, train_epoch_array, val_epoch_array = train(\n",
    "    caption_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    vocab,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    epochs,\n",
    "#     current_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_bleu3_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEGCAYAAACtqQjWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXhV5bX48e8iI2RiSIBAAoFAGGQ2ghOTMjhQELSKV69T1TrVqejVX+29tdZrq4jUinBxwOvQIlrxoq2CgIBaFYKCMgUCBAnzYEgCmbN+f5ydeAgnE5yTnWF9nicPZw/v3mtvzjnrvPt9935FVTHGGGP8oYXbARhjjGk6LKkYY4zxG0sqxhhj/MaSijHGGL+xpGKMMcZvgt0OwE2xsbGalJTkdhjGGNOorF279rCqxvla1qyTSlJSEmlpaW6HYYwxjYqI7KpqmV3+MsYY4zeWVIwxxviNJRVjjDF+06zbVHwpLi4mKyuLgoICt0MxTUh4eDgJCQmEhIS4HYoxAWVJpZKsrCyioqJISkpCRNwOxzQBqsqRI0fIysqiW7dubodjTEDZ5a9KCgoKaNeunSUU4zciQrt27az2a5oFSyo+WEIx/mbvKdNc2OUvY0yjpKoczC1k074ctu7PpU1EKIMSW5McF0lQC0vibrGaSgMzatQoFi9efNK8mTNnctddd1Vbpvwmzssuu4zs7OxT1vnd737H9OnTq933+++/z6ZNmyqm//M//5OlS5fWJXyfVqxYQUxMDIMGDWLAgAGMGTOGgwcPAvDaa69xzz33nFImKSmJ/v37M2jQIAYNGsS9994LnHysAJmZmfTr1w+A1atXV6w/cOBAFi5ceMaxm4ahoLiUDXuO8U7abn7/wSb+7aWvGPLEJwz772XcPG8NT320hYff/Y5xz61iwO8WM3Xulzz10WY++n4fe7PzsXGj6k9AayoicgnwZyAIeFlV/1hp+STgCaAMKAHuV9XPvZYHAWnAHlWd4MwbBMwBwp0yd6nqamfZo8AvgFLgXlU9+du5Ebj22muZP38+48ePr5g3f/58nnnmmVqV/+c//3na+37//feZMGECffv2BeD3v//9aW+rsuHDh/Phhx8C8OijjzJr1iwef/zxast8+umnxMbG1nof/fr1Iy0tjeDgYPbt28fAgQP52c9+RnBw4N7mqoqq0qKF/T7zB1XlQE4hm/fnsHlfDlv25bJ5Xw47Dh+ntMyTGMJDWtCrQxTjz+pI745R9ImPplfHKI4cL2L97mzW785mXdYx5n2eSVFpGQBxUWEMSmzNoMTWDExoTf+EGGJaWk+8QAjYp81JCLOAsUAWsEZEFqnqJq/VlgGLVFVFZACwAOjttfw+YDMQ7TXvaeBxVf1IRC5zpkeJSF9gKnAW0AlYKiIpqloaoEMMiKuuuorHHnuMwsJCwsLCyMzMZO/evVx44YXceeedrFmzhvz8fK666iqfX8rlj56JjY3lySef5PXXXycxMZG4uDjOPvtsAF566SXmzp1LUVERPXr04I033mDdunUsWrSIlStX8oc//IG///3vPPHEE0yYMIGrrrqKZcuWMW3aNEpKSjjnnHOYPXs2YWFhJCUlceONN/LBBx9QXFzMO++8Q+/evU+Jq5yqkpubS48ePfx+7lq1alXxuqCgoMp2jEceeYRFixYRHBzMuHHjmD59OgcOHOCOO+5gx44dAMyePZvzzz+fGTNm8OqrrwJw6623cv/995OZmcmll17K6NGj+fLLL3n//fdZsGABCxYsoLCwkMmTJ9eYMI2n9pFxMI9NXsljy/4cfjxRXLFO59Yt6RPvSSB94qPpHR9FUrsIn5e3WrcKJTkukilDEgAoLCll875cr0STzSebDlSs3z0ugkEJrRmY6PnrEx9FWHBQ4A+8iQtkTWUokKGqOwBEZD4wCahIKqqa57V+BFBRRxWRBOBy4EngQa/1lJ+STAyw13k9CZivqoXAThHJcGL48nQP4PEPNrJpb87pFvepb6do/utnZ1W5vF27dgwdOpSPP/6YSZMmMX/+fK655hpEhCeffJK2bdtSWlrKxRdfzHfffceAAQN8bmft2rXMnz+fb7/9lpKSEoYMGVKRVKZMmcJtt90GwGOPPcYrr7zCr371KyZOnFiRRLwVFBRw0003sWzZMlJSUrjhhhuYPXs2999/PwCxsbF88803vPjii0yfPp2XX375lHg+++wzBg0axJEjR4iIiOC///u/azxXo0ePJijI8yG/8cYbeeCBB2os8/XXX3PLLbewa9cu3njjjVNqKUePHmXhwoVs2bIFEam4VHjvvfcycuRIFi5cSGlpKXl5eaxdu5Z58+bx9ddfo6oMGzaMkSNH0qZNG9LT05k3bx4vvvgiS5YsYdu2baxevRpVZeLEiaxatYoRI0bUGG9zUFH72Jfj1EBy2eKr9tEx+qfk0TGK3vHRZ1SbCAsOqqidlDuWX8z3WcdYn5XNut3ZfJZxmPe+3QNASJDQNz7ak2ScZNM9NoIW1j5TJ4FMKp2B3V7TWcCwyiuJyGTgKaA9niRSbibwMBBVqcj9wGIRmY6nTeh8r/19VWl/nX3s73bgdoAuXbrU/mjqUfklsPKkUv5LecGCBcydO5eSkhL27dvHpk2bqkwqn332GZMnT6749T5x4sSKZRs2bOCxxx4jOzubvLy8ky61+ZKenk63bt1ISUkBPF/ws2bNqkgqU6ZMAeDss8/mvffe87kN78tff/rTn3j44YeZM2dOtfv1dfnLV+3De96wYcPYuHEjmzdv5sYbb+TSSy8lPDy8Ynl0dDTh4eHceuutXH755UyYMAGA5cuX8/rrrwMQFBRETEwMn3/+OZMnTyYiIqLiOD/77DMmTpxI165dOffccwFYsmQJS5YsYfDgwQDk5eWxbdu2ZplUCopL2XYg7+TLV/tzyPZR+7ikX0d6d4ymT3wUXauoffhbTMsQLuwZy4U9Pe8rVWV/ToGnJrP7GOt3Z/P3tVm8/qXneYlRYcEMSIypSDKDE1vTPjq8ul00e4FMKr7eIae0lqnqQmChiIzA074yRkQmAAdVda2IjKpU5E7gAVX9u4hcDbwCjKnD/uYCcwFSU1Orbb2rrkYRSFdccQUPPvgg33zzDfn5+QwZMoSdO3cyffp01qxZQ5s2bbjppptqvO+hqss/N910E++//z4DBw7ktddeY8WKFdVup6ZGzrCwMMDzZVxSUlLtuuBJcFdeeWWN6/nSrl07fvzxx4rpo0eP+mx36dOnDxEREWzYsIHU1NSK+cHBwaxevZply5Yxf/58XnjhBZYvX+5zX9Udd3miKV/v0Ucf5Ze//OXpHFKjVP5lvGVfrufy1X7P5audXrWPliFBpHSM4tKK5OFp+2hIbRkiQnxMS+JjWnJJv3gASsuU7YfyWOdcNluflc3cVTsocY4rPia8IskMTIyhf+cYosIbzjG5LZBJJQtI9JpO4KdLVadQ1VUikiwiscAFwESnzSQciBaRN1X1euBGPG0tAO8A5dda6rS/hiwyMpJRo0Zxyy23cO211wKQk5NDREQEMTExHDhwgI8++ohRo0ZVuY0RI0Zw00038cgjj1BSUsIHH3xQ8aWXm5tLfHw8xcXFvPXWW3Tu7KnQRUVFkZube8q2evfuTWZmJhkZGRVtMCNHjjzt4/v8889JTk4+rbKjRo3izTffZMyYMYgI//u//8vo0aMB2LlzJ4mJiQQHB7Nr1y7S09OpPF5OXl4eJ06c4LLLLuPcc8+taNu5+OKLKy7plZaWcvz48ZPOoaqycOFC3njjjVNiGj9+PL/97W+57rrriIyMZM+ePYSEhNC+ffvTOsaGpqL2UXH5ypNEvGsfCW1a0rtjNJf160hv5/JVfdU+/C2ohZDSIYqUDlFcner5SikoLmXj3pyKJLN+dzYfb9wPgAj0iIusaJsZlNCaXh2jCA1unp03AplU1gA9RaQbsAdPI/q/ea8gIj2A7U5D/RAgFDiiqo8CjzrrjAKmOQkFPIliJLACuAjY5sxfBPxVRGbgaajvCawO2NEF2LXXXsuUKVOYP38+AAMHDmTw4MGcddZZdO/enQsuuKDa8kOGDOGaa65h0KBBdO3aleHDh1cse+KJJxg2bBhdu3alf//+FYlk6tSp3HbbbTz//PO8++67FeuHh4czb948fv7zn1c01N9xxx11Op7yNhVVJSYm5qR2l9dee43333+/YvqrrzxXMb3bVAYMGMDrr7/O7bffzpYtWxg4cCAiQmpqKk899RTgSVZ//OMfCQkJoUWLFrz44oun1GJyc3OZNGkSBQUFqCrPPfccAH/+85+5/fbbeeWVVwgKCmL27Nmcd9553HTTTQwdOhTwNNQPHjyYzMzMk7Y5btw4Nm/ezHnnnQd4fhS8+eabjS6pqCr7jhWwxWn3KE8eOw7l4fxIp2VIEL06RnFpv3j6xP/U8yq6if9SDw8J4uyubTi7a5uKeT8eL+K7PccqOgJ8uuUg767NAiA0uAVndYpmYILT4yyxNUntWjWLm2AlkP23nZrGTDxdil9V1SdF5A4AVZ0jIv8B3AAUA/nAQ95dip1tjMKTVMq7FF+Ip5tyMFCAp0vxWmfZb4Bb+Kl78kfVxZeamqqVB+navHkzffr0OaPjNsaXhvTeKiguZesBT+LwTiDH8k+uffSJj6aP0223d3w0Xdu2sobrKqgqe7Lzf7pstvsY3+85Rn6xpwNqTMsQBiTEMNhJMgMSWhMXFeZy1KdHRNaqaqrPZc35piBLKqY+ufHeKq99lCcNT/ddT9tHee2jVain9tG7YzR94z29rppD7aM+lJSWse1gXsVls3W7j5G+P6fi3Hdu3dKpyXg6A/TrHENEWMN/0El1SaXhR2+MqZWC4lLS9+eecvnKu/aR2NbT9nH5gE4VNZAuVvsImOCgFp7aXnw0U4d6epueKCqpaJ9Z5ySbf3y/D4AWAikdok7qCNCrQxTBQY2nfcaSig+q2iyufZr6488rAqrK3mMFbNmX4zSeexJIpo/ax+UD4iuSR4rVPhqEVqHBnJPUlnOS2lbMO5JXWFGTWb87m8Wb9vN2mueOjPCQFvTrFFPREWBwYmsS2rRssN9Rdvmr0uWvnTt3EhUVZY+/N35TPp5Kbm5uncdTyS/6qe3D+/JVTsFPXbcT27akT0dPm0ffeM9lLKt9NG6qyg9HTzjtM56bNTfsOUZhieexM20jQhmY8FOiGZjQmrYRofUWn7WpVMFXUrGRH00g1GXkx9Iy5Q//2MTKrYdOqX2U32le3oDeq2OU3SPRTBSXlpG+P7eiS/P63cfYejCX8q/wLm1bOQkmhkGJrTmrUwwtQwPz2BlLKlXwlVSMcdvCb7N44O31jEiJY7DzTKo+8dEktrHahzlZXmFJxWNnyrs27z3m+UEc1ELo1SHKc+9MoqdW07N9lF/uHbKkUgVLKqahKSop4+IZK4gKC+HDX11oScTU2cGcAtZnHfPqcZZNrnO5tFVoEP06e2oyF/aIZURK3Gntw3p/GdNIvL3mB3YfzWfezf0soZjT0j46nLF9wxnbtwMAZWVK5pHjTm3mGOt2Z/PaF5kczi087aRSHUsqxjQQJ4pKeH55BkOT2jIqAB920zy1aCF0j4uke1wkkwf/NCzA8cLAjApiScWYBmLeF5kcyi1k9nVDrOehCaiw4KCAjR3TeO6oMaYJO3aimP9ZuZ2Le7cn1ev+BWMaG0sqxjQAc1ZtJ7ewhGnje7kdijFnxJKKMS47mFPAvC92MnFgJ/rER9dcwJgGzJKKMS77y/IMSkqVB8emuB2KMWfMkooxLtp15Dh/W/0DU4cm0rVdRM0FjGngLKkY46LnPtlKcJBw70U93Q7FGL+wpGKMS7bsz+H/1u/lpvO70T463O1wjPELSyrGuGT64nQiw4K5c2Sy26EY4zeWVIxxQVrmUZZuPsgdI5OJaWVPGTZNhyUVY+qZqvL04nRiI8O4+YIkt8Mxxq8sqRhTz1ZuPcTqnUe59+IetAq1JyWZpsWSijH1qKxMeWZxOoltWzL1nC5uh2OM31lSMaYe/eP7fWzcm8MDY1IIDbaPn2l67F1tTD0pLi1jxidb6dUhikmDOrsdjjEBYUnFmHry7tosdh4+zrTxvfwypKsxDZElFWPqQUFxKX9euo0hXVozpk97t8MxJmAsqRhTD17/MpP9OQU8NL63DcBlmjRLKsYEWE5BMS+u2M6IlDjOS27ndjjGBJQlFWMC7OVVO8g+UczDNgCXaQYsqRgTQIfzCnn5851c3j+efp1j3A7HmICzpGJMAL2wPIPCkjIeHGcDcJnmwZKKMQGS9eMJ/vr1D/z87ASS4yLdDseYemFJxZgAmbl0GwjcN8YG4DLNhyUVYwJg24Fc3vsmixvO7Up8TEu3wzGm3lhSMSYAnl2ylVahwdw1uofboRhTryypGONn63Zn8/HG/dw2vDttI0LdDseYemVJxRg/e2bxFtpFhPKL4d3cDsWYemdJxRg/+iLjMF9kHOGu0T2IDLMBuEzzY0nFGD9RVZ7+eAudYsK5bpgNwGWaJ0sqxvjJ4o37WZ91jPvHpBAeEuR2OMa4IqBJRUQuEZF0EckQkUd8LJ8kIt+JyDoRSRORCystDxKRb0XkQ695bzvrrxORTBFZ58xPEpF8r2VzAnlsxngrLVOmL9lKclwEU4bYAFym+QrYRV8RCQJmAWOBLGCNiCxS1U1eqy0DFqmqisgAYAHQ22v5fcBmILp8hqpe47WPZ4FjXutvV9VBfj8YY2rw3jdZZBzMY/Z1QwgOsgsApvkK5Lt/KJChqjtUtQiYD0zyXkFV81RVnckIoPw1IpIAXA687Gvj4hmU4mrgbwGI3ZhaKywpZebSbQxIiOGSfh3dDscYVwUyqXQGdntNZznzTiIik0VkC/AP4BavRTOBh4GyKrY/HDigqtu85nVzLpetFJHhvgqJyO3Opba0Q4cO1eFwjPHtra9+YE92Pg+N72UDcJlmL5BJxdenS0+ZobpQVXsDVwBPAIjIBOCgqq6tZvvXcnItZR/QRVUHAw8CfxWR6MqFVHWuqqaqampcXFztj8YYH/IKS5j1aQbnJ7fjwh6xbodjjOsCmVSygESv6QRgb1Urq+oqIFlEYoELgIkikonnstlFIvJm+boiEgxMAd72Kl+oqkec12uB7YA9b9wE1Kuf7+TI8SKrpRjjCGRSWQP0FJFuIhIKTAUWea8gIj2cthFEZAgQChxR1UdVNUFVk5xyy1X1eq+iY4Atqprlta04p3MAItId6AnsCNzhmebu6PEiXlq1g3F9OzC4Sxu3wzGmQQhY7y9VLRGRe4DFQBDwqqpuFJE7nOVzgCuBG0SkGMgHrvFquK/OVE5toB8B/F5ESoBS4A5VPeqnwzHmFLNXZJBXVMI0GybYmApSu+/wpik1NVXT0tLcDsM0QvuO5TPymRX8bEAnnr16oNvhGFOvRGStqqb6WmYd6o05Dc8v24aqcr8NwGXMSSypGFNHOw7lsSAti+uGdSWxbSu3wzGmQbGkYkwdPfvJVsKCW3C3DcBlzCksqRhTBxv2HOMf3+3jFxd2Iy4qzO1wjGlwLKkYUwfPLE6ndasQbhvR3e1QjGmQLKkYU0tf7zjCyq2HuHNkMtHhIW6HY0yDZEnFmFpQVZ5enE6H6DBuPD/J7XCMabAsqRhTC8s2H2Ttrh+59+KeNgCXMdWwpGJMDcrKlOlL0klq14qrUxNrLmBMM2ZJxZgaLFq/ly37c3lwXC9CbAAuY6plnxBjqlFUUsaMT7bSNz6aCf3j3Q7HmAbPkoox1Xh7zQ/8cPQED43vRYsW9mh7Y2pSY1IRkVYi8lsRecmZ7ukMomVMk3aiqITnl2cwNKkto3rZgG7G1EZtairzgELgPGc6C/hDwCIypoF47V+ZHMot5OFLbAAuY2qrNkklWVWfBooBVDUf30MFG9NkHDtRzJwV27mod3tSk9q6HY4xjUZtkkqRiLTEGV9eRJLx1FyMabLmrNpOTkEJ08bZAFzG1EVtRn78L+BjIFFE3sIzfvxNgQzKGDcdzClg3hc7mTSoE307RbsdjjGNSrVJRURaAG2AKcC5eC573aeqh+shNmNc8ZflGZSUKg+OTXE7FGManWqTiqqWicg9qroA+Ec9xWSMa344coK/rf6Ba85JpGu7CLfDMabRqU2byiciMk1EEkWkbflfwCMzxgUzPkknOEi492IbJtiY01GbNpVbnH/v9pqngA0oYZqULftz+L/1e/nliGQ6RIe7HY4xjVKNSUVVu9VHIMa4bfridCLDgrlzZLLboRjTaNWYVEQkBLgTGOHMWgH8j6oWBzAuY+rV2l1HWbr5IA+N70VMKxuAy5jTVZvLX7OBEOBFZ/rfnXm3BiooY+qTqvKnj9OJjQzj5guS3A7HmEatNknlHFUd6DW9XETWByogY+rbyq2HWL3zKI9PPItWobX5SBhjqlKb3l+lzl30AIhId6A0cCEZU3/KypRnFqeT0KYl1w7t4nY4xjR6tflZ9hDwqYjswHPzY1fg5oBGZUw9+eeGfWzcm8OMqwcSGmwjQRhzpmrT+2uZiPQEeuFJKltU1Z79ZRq94tIynl2ylZQOkUwa1NntcIxpEmoznsrdQEtV/U5V1wOtROSuwIdmTGC9uzaLnYePM21cL4JsAC5j/KI29f3bVDW7fEJVfwRuC1xIxgReQXEpf166jcFdWjO2bwe3wzGmyahNUmkhXiMUiUgQEBq4kIwJvDe+3MX+nAIeHt/bBuAyxo9q01C/GFggInPwPJ7lDjyPwjemUcopKObFFRkM7xnLecnt3A7HmCalNknlP4Db8dxVL8AS4OVABmVMIL28agc/nijm4fG93Q7FmCanNr2/yoA5wBzn6cQJqmr3qZhG6XBeIS9/vpPL+8fTPyHG7XCMaXJq0/trhYhEOwllHTBPRGYEPjRj/G/WpxkUlpTx4DgbgMuYQKhNQ32MqubgGf1xnqqeDYwJbFjG+F/Wjyd466sfuGpIAslxkW6HY0yTVJukEiwi8cDVwIcBjseYgJm5dBsI3DfGBuAyJlBqk1R+j6cHWIaqrnGe/bUtsGEZ41/bDuTy3jdZ3HBuVzq1bul2OMY0WbVpqH8HeMdregdwZSCDMsbfnl2ylVahwdw1uofboRjTpAX0CXoicomIpItIhog84mP5JBH5TkTWiUiaiFxYaXmQiHwrIh96zXvbWX+diGSKyDqvZY86+0oXkfGBPDbTeKzfnc3HG/dz6/ButI2w+3aNCaSADR7h3Hk/CxgLZAFrRGSRqm7yWm0ZsEhVVUQGAAsA75sH7gM2A9HlM1T1Gq99PAscc173BaYCZwGdgKUikmLdn83Ti7fQNiKUW4d3dzsUY5q8QNZUhuJph9mhqkXAfGCS9wqqmqeq6kxG4LljHwARSQAup4obLZ1Hx1wN/M2ZNQmYr6qFqroTyHBiMM3YFxmH+SLjCHeP7kFkmA3AZUygVZtURGSoiJzjvO4rIg+KyGW13HZnYLfXdJYzr/I+JovIFuAfwC1ei2YCDwNlVWx/OHBAVcs7DdR2f7c7l9rSDh06VMtDMY2RqvL04nQ6xYRz3TAbgMuY+lBlUhGR/wKeB2aLyFPAC0Ak8IiI/KYW2/b1lD49ZYbqQlXtDVwBPOHsewJwUFXXVrP9a/mpllKX/c1V1VRVTY2Li6suftPILd54gPW7s7l/TArhIUFuh2NMs1Dd9YCrgEFAGLAfz+NZckTkGeBr4Mkatp0FJHpNJwB7q1pZVVeJSLKIxAIXABOdWlE4EC0ib6rq9QAiEoznZsyzT3d/pmkrLVOmL0knOS6CKUNsAC5j6kt1l79KVLVUVU8A25276lHVfKq+JOVtDdBTRLqJSCieRvRF3iuISI/yx+qLyBA8j9Q/oqqPqmqCqiY55ZaXJxTHGDwjUGZ5zVsETBWRMBHpBvQEVtciTtMEvfdNFhkH8/j1uF4EB9kwwcbUl+pqKkUi0spJKhU1AhGJoRZJRVVLROQePDdOBgGvqupGEbnDWT4Hz/0uN4hIMZAPXOPVcF+dqZx86Qtn2wuATUAJcLf1/GqeCktKmbl0G/07x3Bpv45uh2NMsyJVfYeLSJivseidy1Pxqvp9oIMLtNTUVE1LS3M7DONn877YyeMfbOKNXwxleE9rNzPG30Rkraqm+lpWXU0lQkQivKYVyFbVw8BhfwZojL/kFZbwwvIMzuvejgt7xLodjjHNTnVJZS2eROLdqypSRNYDt6pqZiADM+Z0vPr5To4cL+KhS3rZMMHGuKDKpKKq3XzNF5EpeAbtuiRQQRlzOn48XsRLq3Ywrm8HhnRp43Y4xjRLde4Wo6rvAe0DEIsxZ2T2yu3kFZUwbXwvt0Mxptmqc1IRkcjTKWdMIO07ls///iuTyYM7k9Ihyu1wjGm2qrz8JSIP+pjdBpiI5+56YxqM55dto0yVB8bYMMHGuKm6hvrKP/cUz5311zeF7sSm6dhxKI8FaVn8+7ldSWzbyu1wjGnWqmuof7yqZSISrKolgQnJmLqZ8clWwoJbcLcNwGWM66p7oOTnXq/fqLTYHn9iGoQNe47x4Xf7uOWCbsRFhbkdjjHNXnUN7t43PvartMxuADANwjOL04lpGcJtI2wALmMaguqSilbx2te0MfXu6x1HWLn1EHeNSiamZYjb4RhjqL6hvrWITMaTeFo7Nz2Cp5YSE/DIjKlG+QBcHaLDuPH8JLfDMcY4qksqK/F0Hy5//TOvZasCFpExtbB8y0HW7vqRJyf3swG4jGlAquv9dXNVy0TkysCEY0zNysqUZxank9SuFVenJtZcwBhTb073zvjn/BqFMXWwaP1etuzP5YGxKYTYAFzGNCin+4m03l/GFUUlZcz4ZCt94qP52YBObodjjKnkdJOK9f4yrng7bTc/HD3Bw+N70aKF/bYxpqGp7tlf3+M7eQjQIWARGVOF/KJSnl+2jXOS2jCql43oaExDVF3vrwn1FoUxtTDvXzs5lFvIi9cNsQG4jGmgquv9tavyPGd8+iNa1cD2xgTIsRPFzFmxnYt6t+ecpLZuh2OMqUJ1z/46V0RWiMh7IjJYRDYAG4ADImKjPpp69T+rtpNTUCx84aUAABJLSURBVMK0cTYAlzENWXWXv14A/h+eu+eXA5eq6lci0hv4G/BxPcRnDAdzCpj3RSYTB3aib6dot8MxxlSjut5fwaq6RFXfAfar6lcAqrqlfkIzxuMvyzMoLi3jwbE2AJcxDV11SaXM63V+pWXWpmLqxQ9HTvC31T9wzTmJJMVG1FzAGOOq6i5/DRSRHDxdiFs6r3GmwwMemTHAc0u3Ehwk3HtxT7dDMcbUQnW9v+wpfcZVW/bn8P66Pdw+ojsdou13jDGNgT04yTRY0xenExkWzJ0jk90OxRhTS5ZUTIO0dtdRlm4+yB0jk2ndKtTtcIwxtWRJxTQ4qsrTH6cTGxnGzRckuR2OMaYOLKmYBmfVtsN8vfMov7qoB61Cq+tLYoxpaCypmAalrEx5+uMtJLRpybVDu7gdjjGmjiypmAblnxv2sXFvDg+MSSE02N6exjQ29qk1DUZJaRkzlmwlpUMkVwzu7HY4xpjTYEnFNBjvrs1ix+HjTBvXiyAbgMuYRsmSimkQCopLmbl0G4O7tGZsXxsDzpjGypKKaRDe+HIX+3MKeGh8LxuAy5hGzJKKcV1uQTEvrshgeM9Yzk+OdTscY8wZsKRiXPfSZzv58UQxD4/v7XYoxpgzFNCkIiKXiEi6iGSIyCM+lk8Ske9EZJ2IpInIhZWWB4nItyLyYaX5v3K2u1FEnnbmJYlIvrOtdSIyJ5DHZvzjcF4hr3y2g8v6d6R/Qozb4RhjzlDAblcWkSBgFjAWyALWiMgiVd3ktdoyYJGqqogMABYA3j9X7wM2AxXD/YnIaGASMEBVC0Wkvdf621V1UGCOyATCrE8zyC8u5cGxNkywMU1BIGsqQ4EMVd2hqkXAfDzJoIKq5qlq+YBfEXgN/iUiCcDlwMuVtnsn8EdVLXS2cTBA8ZsAy/rxBG999QM/PzuRHu0j3Q7HGOMHgUwqnYHdXtNZzryTiMhkEdkC/AO4xWvRTOBhTh6BEiAFGC4iX4vIShE5x2tZN+dy2UoRGe4rKBG53bnUlnbo0KHTOCzjL39eug0E7htjA3AZ01QEMqn46hd6yjDEqrpQVXsDVwBPAIjIBOCgqq71sY1goA1wLvAQsEA8fVD3AV1UdTDwIPBXEYmuXFhV56pqqqqmxsXFneahmTOVcTCXv3+Txb+f25VOrVu6HY4xxk8CmVSygESv6QRgb1Urq+oqIFlEYoELgIkikonnstlFIvKm13bfU4/VeGoysapaqKpHnG2tBbbjqdWYBmj64q20DAnirlE2AJcxTUkgk8oaoKeIdBORUGAqsMh7BRHp4dQyEJEhQChwRFUfVdUEVU1yyi1X1eudYu8DFzllUpwyh0UkzukcgIh0B3oCOwJ4fOY0rd+dzccb93PbiO60iwxzOxxjjB8FrPeXqpaIyD3AYiAIeFVVN4rIHc7yOcCVwA0iUgzkA9d4NdxX5VXgVRHZABQBNzq9x0YAvxeREqAUuENVjwbm6MyZeGZxOm0jQrl1eHe3QzHG+JnU/B3edKWmpmpaWprbYTQrX2Qc5rqXv+axy/tYUjGmkRKRtaqa6muZ3VFv6o2q8vTidDrFhHP9uV3dDscYEwCWVEy9WbzxAOt3Z3P/mBTCQ4LcDscYEwCWVEy9KC1Tnl2STnJcBFOG2ABcxjRVllRMvVj47R62Hczj1+N6ERxkbztjmir7dJuA23Ygl+c+2Ur/zjFc2q+j2+EYYwIoYF2Kjdl99ATPLd3Kwm/3EBEazMypg2wALmOaOEsqxu8O5BTwl+XbeHvNblqIcNvw7twxMpm2EaFuh2aMCTBLKsZvfjxexJyV23ntX5mUlilThybyq4t60iE63O3QjDH1xJKKOWN5hSW88tlOXv5sB3lFJUwe1Jn7x6TQpV0rt0MzxtQzSyrmtBUUl/LmV7t4ccV2jh4vYvxZHXhwbC96dYxyOzRjjEssqZg6Ky4t4520LJ5fto39OQUM7xnLr8f1YlBia7dDM8a4zJKKqbWyMuWD7/Yy45Ot7DpygiFdWjPjmoGcnxzrdmjGmAbCkoqpkaqydPNBnl2Szpb9ufTuGMUrN6ZyUe/21kXYGHMSSyqmWv/KOMzTi9NZtzubpHateP7awUzoH0+LFpZMjDGnsqRifPr2hx+ZviSdLzKOEB8Tzh+n9OfKsxMIsUesGGOqYUnFnGTL/hyeXbKVTzYdoF1EKL+d0JfrhnWxpwobY2rFkooBIPPwcZ5bupVF6/cSGRrMr8emcPOF3YgMs7eIMab27Bujmdt3LJ/nl2WwIG03IUHCL0ckc8fI7rRuZY9UMcbUnSWVZupIXiGzV2zn9a92oapcP6wLd4/uQXt7pIox5gxYUmlmcgqKefmznbzy2Q7yi0uZMiSB+y7uSWJbe6SKMebMWVJpJvKLSnn9y0xmr9xO9oliLuvfkQfHptCjvT1SxRjjP5ZUmriikjLeTtvNX5Zt42BuISNT4pg2rhf9E2LcDs0Y0wRZUmmiSsuU/1u3h+eWbmX30XzOSWrDX64dzLDu7dwOzRjThFlSaWJUlcUb9/Pskq1sO5jHWZ2imXdzP0alxNkjVYwxAWdJpYlQVT7bdpjpS9L5LusY3eMimPVvQ7i0X0d7pIoxpt5YUmkC1u46ytMfp/P1zqN0bt2Sp68awJTBnQm2R6oYY+qZJZVGbOPeYzy7ZCvLtxwkNjKMxyeexdShiYQF2yNVjDHusKTSCO04lMeMT7by4Xf7iA4P5uFLenHT+Um0CrX/TmOMu+xbqBHZk53P80u38e43WYQGteCe0T24bUR3YlqGuB2aMcYAllQahcN5hcz6NIO3vvoBgBvO68pdo3oQFxXmcmTGGHMySyoN2LH8Yl5atYNXv9hJQXEpPz87kXvH9KRz65Zuh2aMMT5ZUmmAThSV8Nq/MpmzYjs5BSVMGBDPA2NTSI6LdDs0Y4ypliWVBqSwpJT5q3fzl+UZHM4r5KLe7fn1uBTO6mSPVDHGNA6WVBqAktIyFn67h5lLt7EnO5+h3doy5/ohpCa1dTs0Y4ypE0sqLiorUz7asJ8Zn6Sz/dBx+neO4akp/RneM9YeqWKMaZQsqbhAVVmx9RDTF6ezcW8OPdpHMuf6IYw/q6MlE2NMo2ZJpZ6t3nmUZxZvYU3mjyS2bcmzPx/IFYM7E2TP5zLGNAGWVOrJhj3HeGZxOiu3HqJ9VBhPXNGPa1ITCQ2253MZY5oOSyoBlnEwlxmfbOWf3++ndasQHr20Nzecl0TLUHs+lzGm6Qnoz2QRuURE0kUkQ0Qe8bF8koh8JyLrRCRNRC6stDxIRL4VkQ8rzf+Vs92NIvK01/xHnX2li8j4wB1ZzXYfPcG0d9Yz7rlVrEw/xL0X92TVw6P55chkSyjGmCYrYDUVEQkCZgFjgSxgjYgsUtVNXqstAxapqorIAGAB0Ntr+X3AZiDaa7ujgUnAAFUtFJH2zvy+wFTgLKATsFREUlS1NFDH6MvB3AJmLc/gr6t/QES45YJu3DkqmXaR9kgVY0zTF8jLX0OBDFXdASAi8/Ekg4qkoqp5XutHAFo+ISIJwOXAk8CDXuvdCfxRVQudbRx05k8C5jvzd4pIhhPDl34+Lp+yTxTxP6t2MO+LnRSXKlenJnLvxT2Ij7FHqhhjmo9AJpXOwG6v6SxgWOWVRGQy8BTQHk8SKTcTeBiIqlQkBRguIk8CBcA0VV3j7O+rSvvr7GN/twO3A3Tp0qVuR+TD8cISXv18J3NX7SCvqISJAzvxwJgUkmIjznjbxhjT2AQyqfjqI6unzFBdCCwUkRHAE8AYEZkAHFTVtSIyqlKRYKANcC5wDrBARLrXYX9zgbkAqamppyyvrYLiUv769Q/M+jSDI8eLGNOnA78el0Kf+OiaCxtjTBMVyKSSBSR6TScAe6taWVVXiUiyiMQCFwATReQyIByIFpE3VfV6Z7vvqaoCq0WkDIit6/7OxPrd2dz55lr2Hivg/OR2TBvfiyFd2gRiV8YY06gEsvfXGqCniHQTkVA8jeiLvFcQkR7i3EIuIkOAUOCIqj6qqgmqmuSUW+4kFID3gYucMilOmcPOtqeKSJiIdAN6AqsDcWBJ7SJIbh/JW7cO46+3nWsJxRhjHAGrqahqiYjcAywGgoBXVXWjiNzhLJ8DXAncICLFQD5wjVMDqc6rwKsisgEoAm50ymwUkQV4OgKUAHcHqudXTKsQ3vjFKc1DxhjT7EnN3+FNV2pqqqalpbkdhjHGNCoislZVU30ts2eEGGOM8RtLKsYYY/zGkooxxhi/saRijDHGbyypGGOM8RtLKsYYY/zGkooxxhi/adb3qYjIIWDXGWwiFs/d/A2NxVU3FlfdWFx10xTj6qqqcb4WNOukcqZEJK2qG4DcZHHVjcVVNxZX3TS3uOzylzHGGL+xpGKMMcZvLKmcmbluB1AFi6tuLK66sbjqplnFZW0qxhhj/MZqKsYYY/zGkooxxhi/saRSiYgkisinIrJZRDaKyH3O/J8702UiUmU3PBG5RETSRSRDRB5pQHFlisj3IrJORPw2iEw1cT0jIltE5DsRWSgirasoX9/nq7Zx1ff5esKJaZ2ILBGRTlWUr+/zVdu46vV8eS2fJiLqDEPuq3y9nq86xFXf76/ficgeZ3/rxDNUu6/yZ36+VNX+vP6AeGCI8zoK2Ar0BfoAvYAVQGoVZYOA7UB3PMMcrwf6uh2XUyYTiK3H8zUOCHbm/wn4UwM5XzXG5dL5ivZa515gTgM5XzXG5cb5cqYT8Ywsu8vXvt04X7WJy6X31++AaTWU9cv5sppKJaq6T1W/cV7nApuBzqq6WVXTayg+FMhQ1R2qWgTMByY1gLgCppq4lqhqibPaV0CCj+JunK/axBUw1cSV47VaBOCrB40b56s2cQVMVXE5i58DHq4mpno/X7WMK2BqiKsmfjlfllSqISJJwGDg61oW6Qzs9prOovb/obV2GnGB5w2+RETWisjt/o6phrhuAT7yUcTt81VVXODC+RKRJ0VkN3Ad8J8+irhyvmoRF9Tz+RKRicAeVV1fTZF6P1+1jAvc+Tze41zKfFVE2vgo4pfzZUmlCiISCfwduL/Sr7Vqi/mY59dfK6cZF8AFqjoEuBS4W0RG1EdcIvIboAR4y1cxH/Pq5XzVEBe4cL5U9TeqmujEdI+vYj7mBfx81SIuqMfzhef/7TdUneAqivmYF7DzVYe4oP7fX7OBZGAQsA941lcxH/PqfL4sqfggIiF4/kPeUtX36lA0C8/11HIJwN4GEBequtf59yCwEE9VN6BxiciNwATgOnUu2lbiyvmqRVyunC8vfwWu9DHf7fdXVXHV9/lKBroB60UkE895+EZEOlYqWt/nq7Zx1fv7S1UPqGqpqpYBL1WxP/+cL383FDX2PzzZ+nVgZhXLV1B1Q30wsAPPG6u8oeusBhBXBBDl9fpfwCWBjAu4BNgExFVTtt7PVy3jcuN89fR6/Svg3QZyvmoTV72fr0rrZOK7od61z2MNcbnx/or3ev0AMD9Q5+uMD6Kp/QEX4qnyfQesc/4uAybjyeSFwAFgsbN+J+CfXuUvw9PjYjvwm4YQF57eHOudv431FFcGnuuz5fPmNJDzVWNcLp2vvwMbnPkf4Gkkbwjnq8a43DhfldbJxPnydvt81SYul95fbwDfO/MX4SSZQJwve0yLMcYYv7E2FWOMMX5jScUYY4zfWFIxxhjjN5ZUjDHG+I0lFWOMMX5jScWYABORUq+nw67z89Nyk0Rkg7+2Z8yZCnY7AGOagXxVHeR2EMbUB6upGOMSZ0yNP4nIauevhzO/q4gscx7+t0xEujjzO4hnDJj1zt/5zqaCROQlZ/yMJSLS0rWDMs2eJRVjAq9lpctf13gty1HVocALwExn3gvA66o6AM9DHJ935j8PrFTVgcAQPHdjA/QEZqnqWUA2VTyfy5j6YHfUGxNgIpKnqpE+5mcCF6nqDuchgPtVtZ2IHMbzGI1iZ/4+VY0VkUNAgqoWem0jCfhEVXs60/8BhKjqHwJ/ZMacymoqxrhLq3hd1Tq+FHq9LsXaSo2LLKkY465rvP790nn9L2Cq8/o64HPn9TLgTgARCRKR6PoK0pjasl80xgReSxFZ5zX9saqWdysOE5Gv8fzAu9aZdy/wqog8BBwCbnbm3wfMFZFf4KmR3IlnwCVjGgxrUzHGJU6bSqqqHnY7FmP8xS5/GWOM8RurqRhjjPEbq6kYY4zxG0sqxhhj/MaSijHGGL+xpGKMMcZvLKkYY4zxm/8PERXf7woAJ+wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(val_epoch_array, val_bleu3_array, label = 'Validation BLEU3 score')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('BLEU3 score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_score(reference, hypothesis):\n",
    "\n",
    "    evaluator = rouge.Rouge(metrics=['rouge-l'])\n",
    "    return evaluator.get_scores([hypothesis], [reference])['rouge-l']['f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, val_loader, vocab, beam=5):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    rouge_scores = []\n",
    "    bleu1_scores = []\n",
    "    bleu2_scores = []\n",
    "    bleu3_scores = []\n",
    "    bleu4_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, semantic_inputs, captions, lengths) in enumerate(val_loader):\n",
    "            images = images.to(device)\n",
    "            semantic_inputs = semantic_inputs.to(device)\n",
    "            captions = captions.to(device)\n",
    "            caption = captions[0]\n",
    "            \n",
    "            image_feats = encoder(images)\n",
    "            image_feats = image_feats.unsqueeze(1).squeeze(3).squeeze(3)\n",
    "            \n",
    "            caption_list = [vocab.get_word(wid.item()) for wid in caption if wid != 0]                \n",
    "            caption_list = caption_list[:-1]\n",
    "            caption_sentence = ' '.join(caption_list)\n",
    "            \n",
    "            output = model(image_feats, 14, semantic_inputs, None, beam=beam)\n",
    "            output = output[1][1:-1] if output[1][-1] == end_token else output[1][1:]\n",
    "            output_sentence = ' '.join(output)\n",
    "\n",
    "            rouge_scores.append(rouge_score(caption_sentence, output_sentence))\n",
    "            bleu1_scores.append(bleu_score(caption_list, output, 1))\n",
    "            bleu2_scores.append(bleu_score(caption_list, output, 2))\n",
    "            bleu3_scores.append(bleu_score(caption_list, output, 3))\n",
    "            try:\n",
    "                bleu4_scores.append(bleu_score(caption_list, output, 4))\n",
    "            except:\n",
    "                bleu4_scores.append(0)\n",
    "            \n",
    "#             if i % 500 == 0:\n",
    "#                 print(i)\n",
    "            \n",
    "            print(\"Ref:\", caption_sentence)\n",
    "            print(\"Hyp:\", output_sentence)\n",
    "#             if i == 5:\n",
    "#                 break\n",
    "\n",
    "    rouge_score_avg = sum(rouge_scores)/len(rouge_scores)\n",
    "    bleu1_score_avg = sum(bleu1_scores)/len(bleu1_scores)\n",
    "    bleu2_score_avg = sum(bleu2_scores)/len(bleu2_scores)\n",
    "    bleu3_score_avg = sum(bleu3_scores)/len(bleu3_scores)\n",
    "    bleu4_score_avg = sum(bleu4_scores)/len(bleu4_scores)\n",
    "    \n",
    "    return rouge_score_avg, bleu1_score_avg, bleu2_score_avg, bleu3_score_avg, bleu4_score_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ref: mr men men mr noisy blue t-shirt\n",
      "Hyp: mr forgetful t-shirt\n",
      "Ref: ice unisex sili pink watch\n",
      "Hyp: ice unisex sili pink watch\n",
      "Ref: playboy women playmate lavender ankle socks\n",
      "Hyp: playboy women playmate pink ankle socks\n",
      "Ref: vishudh women printed purple kurta\n",
      "Hyp: women printed kurta\n",
      "Ref: wildcraft unisex black and grey backpack\n",
      "Hyp: wildcraft unisex acute backpack\n",
      "Ref: pitaraa golden fish scale necklace\n",
      "Hyp: pitaraa golden necklace\n"
     ]
    }
   ],
   "source": [
    "id_ = [19766,\n",
    " 32863,\n",
    " 2845,\n",
    " 32272,\n",
    " 32157,\n",
    " 48332,]\n",
    "test_df = df[df.id.isin(id_)]\n",
    "file_names_train = test_df['file_name'].values\n",
    "semantic_inputs_train = test_df['tags_pred'].values\n",
    "labels_train = test_df['tokenized'].values\n",
    "\n",
    "test_dataset = FullProductDataset(file_names_train, semantic_inputs_train, labels_train, \"data/images\", vocab, image_transformer)\n",
    "pred_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "rouge_score_avg, bleu1_score_avg, bleu2_score_avg, bleu3_score_avg, bleu4_score_avg = predict(caption_model, pred_loader, vocab, beam=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=0, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n"
     ]
    }
   ],
   "source": [
    "rouge_score_avg, bleu1_score_avg, bleu2_score_avg, bleu3_score_avg, bleu4_score_avg = predict(caption_model, pred_loader, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8182926373525539 0.7462955313405971 0.6445285127957694 0.48590717073530787 0.381240535966444\n"
     ]
    }
   ],
   "source": [
    "print(rouge_score_avg, bleu1_score_avg, bleu2_score_avg, bleu3_score_avg, bleu4_score_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
